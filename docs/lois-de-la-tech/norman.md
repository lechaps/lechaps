# Norman

Tu as déjà tiré une porte marquée « PUSH » ?  
Ou cliqué dix fois sur un bouton sans comprendre pourquoi "ça ne marche pas" ?  
Bienvenue dans **la "loi de Norman"** — ou, plus rigoureusement : **la théorie de l'action de Norman**.

Norman ne résume pas ça en une formule magique. Il propose un modèle très concret : **un humain accomplit une tâche en passant par 7 étapes**, du but à l'évaluation du résultat.

Bref : **si quelqu'un se trompe, ce n'est pas qu'il est "nul" — c'est souvent que le système n'aide pas assez à franchir ces étapes.**

## Pourquoi la théorie de l'action est si parlante

Parce qu'elle décrit ce qui se passe *vraiment* dans la tête d'une personne quand elle agit :

1. elle se fixe un but,
2. elle forme une intention,
3. elle spécifie une suite d'actions,
4. elle exécute,
5. elle perçoit l'état du système,
6. elle interprète cet état,
7. elle évalue si ça correspond au but.

Et là, tu vois tout de suite le piège :

* Si le système n'aide pas à **trouver l'action**, on bloque côté *exécution*.
* Si le système n'aide pas à **comprendre ce qui s'est passé**, on bloque côté *évaluation*.

Autrement dit : **l'erreur utilisateur est souvent une erreur de design**… parce que le design laisse un "trou" dans une des étapes.

## Les 7 étapes, vues comme une grille UX

### Côté exécution

Le but doit être transformé en intention, puis en une séquence d'actions, puis exécuté. Si l'interface est floue, l'utilisateur se retrouve à :

* deviner "où cliquer",
* tester au hasard,
* mémoriser des règles cachées.

### Côté évaluation

Après l'action, l'utilisateur doit percevoir l'état du système, l'interpréter, puis le comparer au but. Sans feedback clair :

* il doute,
* il répète,
* il perd confiance.

Dans l'exemple de Norman : on allume une lampe, puis on évalue si elle est bien allumée. C'est simple, mais ça illustre parfaitement le point : **agir ne suffit pas, il faut pouvoir vérifier et comprendre le résultat.**

## Norman appliqué au numérique

La théorie de l'action te donne une checklist simple :

* Est-ce que l'utilisateur peut **déterminer l'état du système** ?
* Est-ce qu'il peut **savoir s'il est dans l'état désiré** ?
* Est-ce qu'il comprend **les fonctionnalités disponibles** ?
* Est-ce qu'il peut **déduire la séquence d'actions** ?
* Est-ce qu'il peut **exécuter facilement** ?

Si tu réponds "non" à l'une de ces questions, tu sais déjà où vont naître :

* les erreurs,
* les hésitations,
* les tickets support,
* les "je comprends rien à votre truc".

## Avec l'IA, ça devient encore plus critique

L'IA peut rendre l'exécution "facile" (tu demandes, ça fait).
Mais elle complique l'évaluation :

* "Qu'est-ce qu'elle a compris ?"
* "Sur quoi elle s'est basée ?"
* "Est-ce que je peux vérifier ?"
* "Pourquoi ça a fait ça ?"

Donc le design doit redoubler d'efforts sur **perception → interprétation → évaluation** : rendre visible l'état, les changements, et ce qui permet de juger le résultat par rapport au but. (C'est exactement le dernier tiers des 7 étapes.)

## D'où vient la "loi de Norman" ?

De **Donald Norman**, consultant en utilisabilité, qui définit cette **théorie de l'action** dans *The Design of Everyday Things*.  
Elle est aussi appelée en anglais **"Seven stages of action"** et sert à modéliser la psychologie d'une personne qui réalise une tâche.

En résumé, si on veut en faire une "loi" mémorisable, la version fidèle serait :

**Un produit est bon quand il aide l'utilisateur à traverser les 7 étapes : agir facilement, puis comprendre et évaluer clairement ce qui s'est passé.**

## Et si la plupart des "erreurs utilisateur" étaient des erreurs de complexité… ou de choix ?

La théorie de l'action de Norman montre où naissent les frictions : quand l'utilisateur ne sait pas quoi faire, ou ne peut pas évaluer ce qui s'est passé.  
Mais ces frictions sont souvent causées en amont :

* par une complexité mal placée (Tesler),
* par un trop grand nombre d'options non structurées (Hick-Hyman).

Ces trois lois décrivent la même réalité, vue à trois étages : qui porte la complexité, comment on décide, et comment on agit et on comprend.

**[Lire la suite : Tesler × Hick-Hyman × Norman — UX](../humanops/ux.md)**

### Références

* [Wikipédia - Théorie de l'action (Norman)](https://fr.wikipedia.org/wiki/Th%C3%A9orie_de_l%27action_%28Norman%29){ target="_blank" }
