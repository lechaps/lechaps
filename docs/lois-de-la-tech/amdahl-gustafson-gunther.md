# Amdahl, Gustafson & Gunther

## Les trois lois qui gouvernent vraiment la performance et le scaling

Il existe trois lois qui expliquent pourquoi certains syst√®mes plafonnent ‚Äî et pourquoi d'autres, au contraire, s'envolent lorsqu'on ajoute des ressources.

Trois lois utilis√©es en HPC, en architecture logicielle, en scaling d'√©quipes, en data engineering, en infra distribu√©e.

Elles forment un cadre strat√©gique simple :

> **Optimiser agit sur le temps.
> Scaler agit sur la capacit√©.
> Et la r√©alit√© impose toujours une limite.**

Les lois d'Amdahl, de Gustafson et de Gunther sont compl√©mentaires :
**Amdahl montre la barri√®re.
Gustafson montre l'horizon.
Gunther montre le co√ªt r√©el du voyage.**

## 1. Amdahl : tu n'iras jamais plus vite que ton maillon le plus lent

Tu optimises un √©l√©ment ‚Äî mais le r√©sultat global ne d√©colle pas.
C'est normal : ce n'√©tait pas le goulot.

> The overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used. ‚Äî Gene M. Amdahl, 1967

**Autrement dit :**
**Tu peux optimiser autant que tu veux : si la partie critique reste lente, tout reste lent.**

**Le gain maximal d'un syst√®me est limit√© par la proportion de travail non parall√©lisable.**

Plus un segment est s√©quentiel, plus il bride l'ensemble.

### Le sch√©ma mental

> **Amdahl ‚Üí "Qu'est-ce qui ralentit ?"**

### Optimiser ‚â† Scaler

* **Optimiser = r√©duire la quantit√© de travail**.
* **Scaler = augmenter le nombre de travailleurs**.

Amdahl concerne le premier.

### Exemple simple

Si 30 % du traitement reste s√©quentiel, m√™me 100 processeurs n'offrent qu'un facteur d'environ **3,3x**.
Un plafond dur.

### Version organisationnelle

* Une √©quipe brillante reste lente si la coordination est complexe.
* Une cha√Æne automatis√©e reste bloqu√©e si la logistique tra√Æne.
* Un CTO peut ajouter 10 devs‚Ä¶ mais pas r√©duire les d√©pendances.

> **Optimiser, c'est r√©duire la friction.
> Mais la friction a un plancher.**

### D'o√π vient la loi d'Amdahl

Gene M. Amdahl (1922‚Äì2015), architecte informatique majeur chez IBM, formalise la loi en 1967 dans *"Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities."*
Il y oppose la vision ‚Äî alors dominante ‚Äî qui pensait que "plus de processeurs = plus de performance".
Amdahl d√©montre au contraire que **le s√©quentiel est une limite absolue**, quelle que soit la quantit√© de ressources ajout√©es.

## 2. Gustafson : agrandir le probl√®me pour lib√©rer la vitesse

Gustafson inverse la perspective.
Il ne demande pas : *"Combien plus vite ?"*
Il demande : *"Qu'est-ce que je pourrais accomplir de plus ?"*

La formulation standard de la loi : 

> We don't speed up the old problem; we solve bigger problems in the same time."* ‚Äî John L. Gustafson, 1988

**Autrement dit :**
**Le parall√©lisme permet moins d'acc√©l√©rer ce qu'on faisait d√©j√† que d'augmenter radicalement ce qu'on est capable de faire.**

**Un syst√®me parall√©lis√© peut traiter beaucoup plus de travail dans le m√™me temps.**

Ce n'est pas la vitesse du probl√®me initial qui compte, mais la capacit√© √† agrandir le probl√®me.

### Le sch√©ma mental

> **Gustafson ‚Üí "Que pourrions-nous faire de plus ?"**

### Le renversement

* Amdahl ‚Üí taille fixe du probl√®me.
* Gustafson ‚Üí taille variable.

### Exemple concret

Pipeline data :

* Optimisation ‚Üí 100k ‚Üí 120k √©v√©nements/min.
* Scaling horizontal ‚Üí 1M √©v√©nements/min.

On n'a pas acc√©l√©r√© l'ancien probl√®me.
On a **chang√© d'√©chelle**.

### Version organisationnelle

* Plus de squads = plus de sujets trait√©s en parall√®le.
* Plus de GPU = mod√®les plus grands, plus riches, plus ambitieux.

> **Gustafson ne nie pas la limite ‚Äî il invite √† la d√©passer en changeant d'√©chelle.**

### D'o√π vient la loi de Gustafson

John L. Gustafson publie sa loi en 1988 dans *"Reevaluating Amdahl's Law."*
Il y critique la vision strictement pessimiste d'Amdahl, en observant que les syst√®mes parall√®les n'acc√©l√®rent pas des probl√®mes constants :
**ils permettent d'attaquer des probl√®mes plus grands.**
Cette vision ouvre la voie au *scaled computing* moderne.

## 3. Gunther : le scaling r√©el n'est jamais gratuit

Amdahl et Gustafson sont puissants, mais incomplets.
Il manquait une loi qui mod√©lise le monde r√©el :

* latence,
* contention,
* coordination,
* coh√©rence,
* trafic r√©seau,
* invalidation de caches.

C'est ce que Gunther apporte en 1993 avec *Universal Scalability Law*

> A system's capacity is limited by contention and by the coherency delay introduced as the number of processors increases. ‚Äî Neil J. Gunther, 1993

**Autrement dit :**
**M√™me si un syst√®me est parall√©lisable, le co√ªt de coordination finit par annuler ‚Äî voire inverser ‚Äî les gains du scaling.**

**Le scaling r√©el est limit√© par deux forces : la contention et la coh√©rence.**

La loi pr√©dit trois zones :

1. **Scaling lin√©aire** (rare).
2. **Diminishing returns** (les gains se tassent).
3. **Retrograde scaling** (ajouter des ressources ralentit le syst√®me).

### Le sch√©ma mental

> **Gunther ‚Üí "Quel est le co√ªt de la coordination ?"**

### Exemple

√Ä mesure qu'un cluster microservices s'agrandit :

* plus de latence r√©seau,
* plus de synchronisation,
* plus de contention,
* plus de cache invalidation,

jusqu'√† un point o√π **ajouter des n≈ìuds d√©grade la performance**.

C'est le domaine de Gunther.

### Version organisationnelle

Plus d'√©quipes ‚Üí plus de coordination ‚Üí plus de d√©pendances ‚Üí plus de meetings ‚Üí vitesse effective r√©duite.

> **Gunther relie ing√©nierie et management :
> Scaler augmente toujours la complexit√©.**

### D'o√π vient la loi

Neil J. Gunther, physicien et sp√©cialiste des syst√®mes distribu√©s, publie l'Universal Scalability Law en 1993.
Il cherche alors √† d√©passer Amdahl et Gustafson en int√©grant les ph√©nom√®nes r√©els de coordination.
Sa loi devient la base du capacity planning moderne.

## 4. Le trio d√©cisionnel : quand penser Amdahl, Gustafson ou Gunther ?

Voici un arbtre de d√©cision applicable √† un syst√®me, un produit ou une organisation.

### √âtape 1 ‚Äî Le r√©sultat n'augmente pas ?

üëâ **Amdahl** : identifie le goulot, supprime-le, simplifie.

### √âtape 2 ‚Äî Le besoin d√©passe la capacit√© ?

üëâ **Gustafson** : parall√©lise, distribue, scale horizontalement.

### √âtape 3 ‚Äî Le scaling devient chaotique ou inefficace ?

üëâ **Gunther** : mesure les co√ªts, r√©duit la contention, re-pense la topologie.

## 5. Optimiser vs Scaler : le cadre mental final

Une phrase suffit pour comprendre les trois lois :

> **Optimiser agit sur le temps.
> Scaler agit sur la capacit√©.
> Gunther te rappelle que tu paies la coordination.**

Ou en version "leaders tech" :

* **Amdahl = identifier le frein.**
* **Gustafson = ouvrir la route.**
* **Gunther = √©viter les accidents.**

## 6. La synth√®se strat√©gique

## Le progr√®s n'est jamais seulement une acc√©l√©ration ‚Äî c'est un changement d'√©chelle ma√Ætris√©

Ces lois forment une pens√©e syst√©mique :

* **Amdahl** montre ce qu'il faut r√©duire.
* **Gustafson** montre ce qu'il faut agrandir.
* **Gunther** montre ce qu'il faut contr√¥ler.

Et leur tension fa√ßonne toutes les architectures modernes :

| Domaine           | Amdahl (friction)                  | Gustafson (capacit√©)     | Gunther (co√ªt)             |
| ----------------- | ---------------------------------- | ------------------------ | -------------------------- |
| **LLM**           | Optimisation mod√®le (quantization) | + GPU = mod√®les + grands | Synchronisation multi-GPU  |
| **Data**          | Index, cache, partitioning         | + workers ‚Üí throughput   | Shuffle / cross-node costs |
| **Microservices** | Optimiser la latence interne       | Multiplier les n≈ìuds     | Surco√ªt RPC                |
| **Organisation**  | Simplifier, r√©duire d√©pendances    | + squads = + features    | Meetings, coordination     |

> **Pas de scale sans design.
> Pas de vitesse sans simplification.
> Pas de croissance sans limites.**

### R√©f√©rences

* [Gene M Amdahl - Validity of the single processor approach to achieving large scale
computing capabilities, 1967](https://safari.ethz.ch/digitaltechnik/spring2022/lib/exe/fetch.php?media=amdahl.pdf){ target="_blank" }
* [Amdahl's law - wikip√©dia](https://en.wikipedia.org/wiki/Amdahl%27s_law){ target="_blank" }
* [Retrospective on Amdahl's Law in the Multicore Era](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945175){ target="_blank" }
* [Reevaluating Amdahl's Law - John L. Gustafson](http://www.johngustafson.net/pubs/pub13/amdahl.htm){ target="_blank" }
* [Gustafson's law - wikip√©dia](https://en.wikipedia.org/wiki/Gustafson%27s_law){ target="_blank" }
* [Gunther's law - wikip√©dia](https://en.wikipedia.org/wiki/Neil_J._Gunther#Universal_Scalability_Law){ target="_blank" }
* [A simple Capacity model of massively parallel transaction systems - Neil J. Gunther](http://www.perfdynamics.com/Papers/njgCMG93.pdf){ target="_blank" }
