# Goodhart

Tu as déjà vu une équipe se battre pour atteindre un chiffre… au point d'en oublier pourquoi elle le poursuit ?
On fixe un objectif, on fait des tableaux, on compte tout — et petit à petit, on ne cherche plus à s'améliorer, mais juste à faire gonfler la métrique.
Bienvenue dans **la loi de Goodhart**.

> When a measure becomes a target, it ceases to be a good measure - Charles Goodhart, 1975

Autrement dit : quand on confond le thermomètre avec la température, **on finit par fausser les deux**.

## Pourquoi la loi de Goodhart est si parlante

Une mesure est utile tant qu'elle sert à **comprendre la réalité**.
Dès qu'elle devient un but en soi, elle change de nature : **elle influence les comportements qu'elle était censée observer**.

C'est là que les dérives apparaissent :

* **Gaming des indicateurs** : on optimise le chiffre, pas le travail réel.
* **Substitution d'objectif** : la métrique remplace la mission.
* **Optimisation locale** : on améliore un point au détriment du système global.

Quelques exemples classiques :

* **Dans une entreprise** : si l'objectif est le nombre d'appels, les conversations sont raccourcies, la qualité chute, la satisfaction client aussi.
* **À l'école** : si seule la note compte, les élèves apprennent à réussir l'examen, pas à comprendre le sujet.
* **En politique publique** : on améliore des statistiques visibles plutôt que de résoudre les problèmes de fond.

Résultat : on crée **des systèmes performants sur le papier**, mais inefficaces — voire contre-productifs — dans la réalité.
La loi de Goodhart rappelle que **les chiffres doivent servir la vision**, pas la remplacer.

## Le paradoxe central : peut-on piloter sans chiffres ?

La loi de Goodhart ne dit pas que mesurer est une erreur.
Elle pose une question bien plus dérangeante :

> **Comment piloter avec des indicateurs… sans se laisser gouverner par eux ?**

Car les chiffres sont indispensables :

* pour comparer,
* pour décider,
* pour rendre compte.

Mais dès qu'un indicateur devient contractuel, incitatif ou punitif, il est **structurellement vulnérable**.
Les acteurs adaptent leur comportement non pas au sens du travail, mais à la cible chiffrée.

Le problème n'est donc pas la mesure, c'est **l'illusion qu'un chiffre peut contenir toute la réalité**.

## D'où vient la loi de Goodhart ?

Le principe vient de **Charles Goodhart**, économiste britannique et ancien conseiller de la Banque d'Angleterre.  
En 1975, il observe que dès qu'un indicateur monétaire devient un objectif officiel, il cesse d'être fiable : les acteurs économiques modifient leur comportement pour atteindre la cible — même si cela fragilise le système.

Formulée dans *Problems of Monetary Management: The U.K. Experience*, cette intuition a ensuite été généralisée :

* par **Donald T. Campbell**, sur les politiques publiques,
* par **Marilyn Strathern**, sur l'audit et l'évaluation académique.

La loi de Goodhart est aujourd'hui centrale dans les réflexions sur :

* les KPI,
* le management par objectifs,
* la gouvernance des données,
* et les systèmes automatisés de décision.

## Comment éviter les pièges de Goodhart ?

Il n'existe pas de solution parfaite, mais plusieurs **principes de vigilance** :

* **Multiplier les indicateurs**, plutôt que de sacraliser un KPI unique.
* Combiner **quantitatif et qualitatif**.
* Traiter les métriques comme des **signaux**, pas comme des verdicts.
* Réviser régulièrement les indicateurs : une bonne mesure aujourd'hui peut devenir toxique demain.
* Laisser une place au **jugement humain**, surtout lorsque les enjeux sont complexes.

En clair : **ce qui est facile à mesurer n'est pas toujours ce qui compte**, et ce qui compte vraiment résiste souvent à la mesure simple.

## En somme

La loi de Goodhart nous rappelle qu'à force de viser le chiffre, **on finit par manquer le sens**.
Les indicateurs doivent :

* éclairer la route,
* nourrir la réflexion,
* soutenir la décision.

Mais ils ne doivent jamais devenir la destination.

## Et si le problème n'était pas seulement la métrique… mais le système qu'elle façonne ?

La loi de Goodhart montre comment un indicateur perd sa valeur dès qu'il devient une cible.
Mais cette dérive ne s'arrête pas à la fiabilité du chiffre : **elle transforme progressivement tout le système qui s'organise autour de lui**.

Une autre loi explore précisément cette dimension systémique — celle qui explique comment les indicateurs, une fois institutionnalisés, finissent par déformer les pratiques qu'ils étaient censés améliorer.

**[Lire la suite : Goodhart × Campbell — Métriques](../humanops/indicateur.md)**

### Références

* [Charles Goodhart, Problems of Monetary Management: The U.K. Experience*, 1975, Papers in Monetary Economics (Reserve Bank of Australia)](https://link.springer.com/chapter/10.1007/978-1-349-17295-5_4){ target="_blank" }
* [Donald T. Campbell, Assessing the Impact of Planned Social Change, 1979](https://www.sciencedirect.com/science/article/abs/pii/014971897990048X){ target="_blank" }
* [M. Strathern, "Improving Ratings: Audit in the British University System", *European Review*, 1997](https://www.cambridge.org/core/journals/european-review/article/abs/improving-ratings-audit-in-the-british-university-system/FC2EE640C0C44E3DB87C29FB666E9AAB){ target="_blank" }