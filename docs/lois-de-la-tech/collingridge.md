# Collingridge

Tu t’es déjà demandé pourquoi on n’arrive **jamais** à encadrer une technologie au bon moment ?
Pourquoi on laisse filer Internet, les réseaux sociaux, l’IA, la biométrie, puis… on se réveille une décennie plus tard en se demandant comment on en est arrivé là ?

Bienvenue dans **le dilemme de Collingridge**.

> **Quand une technologie est jeune, elle est facile à contrôler mais on ne sait pas encore quels problèmes elle va créer.
> Quand elle est mature, ses effets sont clairs… mais il est devenu presque impossible de la contrôler.**

Bref : **Le moment où il faudrait réguler est précisément celui où on ne sait pas réguler.**

## Pourquoi le dilemme de Collingridge est si puissant

David Collingridge, sociologue britannique, expose ce paradoxe en 1980 dans *The Social Control of Technology*.
Et depuis, il est devenu la boussole (et la hantise) de toutes les discussions sur l’innovation.

### 1. *Au début : flexibilité totale, ignorance totale*

La technologie est fragile, marginale, modifiable.
On pourrait la rediriger, la tester, la repenser.
Mais… personne ne sait encore si elle va devenir incontournable.
Ni quels dommages elle va produire.

Exemples :

* Internet dans les années 90
* Le smartphone en 2007
* L’IA générative en 2020

À ce moment-là, les risques sont invisibles.
Et réguler « trop tôt » ressemble à du freinage inutile.

### 2. *Plus tard : impacts évidents, mais contrôle impossible*

La technologie s’impose, devient un standard, voire une dépendance collective.
On en découvre les effets : bulles informationnelles, surveillance, addictions, pollution numérique, biais algorithmique…

Mais :

* **Changer un système adopté par des milliards coûte une fortune — ou se heurte à des lobbys immenses.**
* **Toucher au cœur d’une infrastructure qu’on utilise tous est politiquement explosif.**

Exemple parfait :
Essaye d’imaginer « débrancher » Facebook, Google, ou TikTok aujourd’hui…
Bonne chance.

## Ce que le dilemme nous enseigne

Collingridge nous rappelle un fait brutal :
**Les technologies évoluent plus vite que notre capacité à les comprendre ou à les gouverner.**

D’où une triple leçon :

1. **On doit agir très tôt, mais sans données parfaites.**
2. **On doit anticiper les risques avant qu’ils n’apparaissent.**
3. **On doit créer des technologies modifiables, réversibles et responsables dès leur conception.**

En d’autres termes :
**Le vrai pouvoir n’est pas dans la régulation tardive — mais dans les choix de design dès le départ.**

Ce principe est au cœur de l’innovation responsable, des politiques sur l’IA, des réflexions sur la biotechnologie, l’énergie, le numérique…. 
C’est la question-clé du futur : *Comment gouverner ce qu’on ne comprend pas encore, avant qu’il soit trop tard ?*

### Références

* David Collingridge, (1981). [The Social Control of Technology](https://www.amazon.com/Social-Control-Technology-David-Collingridge/dp/031273168X){ target="_blank" }
* Audley Genius, (2006) [Collingridge and the dilemma of control: Towards responsible and accountable innovation](https://www.sciencedirect.com/science/article/pii/S0048733317301622){ target="_blank" }
